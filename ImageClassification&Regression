모니터와 젯슨을 연결 해 터미널에 들어간 다음 패키지를 설치하고 Headless Mode에 들어가 주피터랩에 연결할 수 있는 환경을 만들어주어야 한다. 
먼저 패키지를 설치하는 과정을 살펴보겠다.
sudo apt-get update 명령어를 통해 설치되어 있는 패키지를 모두 새버전으로 업그레이드 해준 뒤 sudo apt install python3-pip로 pip(파이썬으로 작성된 패키지 라이브러리를 관리해주는 시스템)을 설치해주고,
sudo pip3 list//설치되어있는 리스트 확인
sudo -H pip3 install -U jetson-stats//설치
rc@rc-desktop:~$ pip3 list| grep jetson//설치 확인
rc@rc-desktop:~$ reboot//리부팅
rc@rc-desktop:~$ jtop
를 차례로 실행해 최종적으로 패키지를 설치해준다.
다음으로 Headless Mode를 실행하는 방법이다.
PS C:\Users\user> ssh dli@192.168.55.1
dli@192.168.55.1's password:
Connection reset by 192.168.55.1 port 22
PS C:\Users\user> ssh dli@192.168.55.1의 명령어를 차례로 실행해주고 각 상황에 따라 요구하는 정보를 입력한다.
성공적으로 수행했다면 dli@dli-desktop:~$ 상태가 된다. 이제
dli@dli-desktop:~$ ls
dli@dli-desktop:~$ mkdir -p ~/nvdli-data
dli@dli-desktop:~$ ls
dli@dli-desktop:~$  echo "sudo docker run --runtime nvidia -it --rm --network host \
    --volume ~/nvdli-data:/nvdli-nano/data \
    --volume /tmp/argus_socket:/tmp/argus_socket \
    --device /dev/video0 \
    nvcr.io/nvidia/dli/dli-nano-ai:v2.0.2-r32.7.1kr" > docker_dli_run.sh
dli@dli-desktop:~$ chmod +x docker_dli_run.sh //파일의 권한을 변경
dli@dli-desktop:~$ ls
을 실행해주고
//Disable ZRAM
sudo systemctl disable nvzramconfig

sudo systemctl set-default multi-user.target//Prevent X-Server from starting

//Create additional 6GB swap file (assume 4GB already for a total of 10GB)
sudo fallocate -l 6G /mnt/6GB.swap
sudo chmod 600 /mnt/6GB.swap
sudo mkswap /mnt/6GB.swap

//Append the following line to /etc/fstab
sudo su
echo "/mnt/6GB.swap swap swap defaults 0 0" >> /etc/fstab
exit

//REBOOT!

//Check your memory and swap
free -h

dli@dli-desktop:~$ ./docker_dli_run.sh
를 실행해주면 완성이다. 
시간을 가지고 기다리면 HeadlessMode로 전환되는 것을 확인할 수 있다. 
이 때 Headless Mode는 GUI를 사용하지 않기 때문에 나노 키트의 메모리 리소스를 절약하고, 모니터, 키보드 및 마우스와 같은 추가 하드웨어의 필요성을 제거함으로써 추가적인 이점을 제공한다. 
그 다음 젯슨에 연결된 노트북의 웹브라우저에서 모니터에 나온 ip주소로 들어가면 주피터랩에 들어갈 수 있다. 
그 상태에서  image classification 과 regression 예제를 수행하면 된다. 
먼저 image classification 에서는 usb camera를 이용해 엄지손가락을 올린 상태와 내린 상태를 구분하는 작업을 실행했다. 
각각의 상태를 수십번 씩 add해주고 학습시켜준 다음 live 모드에서 실험해 볼 수 있었다. 데이터의 양이 절대적으로 적을 수 밖에 없기 때문에 정확성이 많이 뛰어나지는 않았지만 학습 데이터를 많이 추가할 수록 정확성이 높아지는 것을 확인할 수 있었다. 
 regression 에서는 실시간 이미지에서 얼굴 형상의 X,Y좌표를 예측할 수 있는 프로그램을 만들었다.
 그러기 위해 나의 얼굴에서 코, 왼쪽 눈, 오른쪽 눈의 위치를 클릭해 좌표를 형성할 수 있도록 했고 실험해 본 결과  image classification과 마찬가지로 어느정도 옳은 결과가 나왔다. 
